{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map-reduce in `load_summarize_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pisek/miniconda3/envs/py3p12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import html\n",
    "import gradio as gr\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import ChatOllama\n",
    "import tiktoken\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "MAP_TEMPLATE_TXT = \"\"\"Write a detail summary of this text section in bullet points. \n",
    "Use '-' for bullet points and answer only the bullet points.\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "SUMMARY:\"\"\"\n",
    "    \n",
    "COMBINE_TEMPLATE_TXT = \"\"\"Combine these summaries into a final summary in bullet points.\n",
    "Use '-' for bullet points and answer only the bullet points.\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "FINAL SUMMARY:\"\"\"\n",
    "\n",
    "map_prompt_txt = MAP_TEMPLATE_TXT\n",
    "combine_prompt_txt = COMBINE_TEMPLATE_TXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample-text.txt\", \"r\") as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "model = \"llama3.2\"\n",
    "base_url = \"http://localhost:11434\"\n",
    "\n",
    "chunk_size = 2000 # this is in tokens\n",
    "overlap_size = 0 # this is in tokens\n",
    "\n",
    "temperature = 0.5\n",
    "\n",
    "map_num_predict = 256 # number of tokens to predict, Default: 128, -1 = infinite generation, -2 = fill context\n",
    "combine_num_predict = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_splitter(chunk_size: int, overlap_size: int):\n",
    "    return RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=overlap_size)\n",
    "\n",
    "def convert_text_to_tokens(text, encoder=\"gpt-3.5-turbo\"):\n",
    "    enc = tiktoken.encoding_for_model(encoder)\n",
    "    return enc.encode(text)\n",
    "\n",
    "def get_larger_context_size(token_count):\n",
    "    num_ctxes = [1024*i for i in range(1, 100)]\n",
    "    num_ctx = next(ctx for ctx in num_ctxes if ctx > token_count) # pick the first context size that is greater than the token counts\n",
    "    return num_ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_transcript_to_split_docs(transcript, chunk_size, overlap_size):\n",
    "    docs = [Document(\n",
    "        page_content=transcript,\n",
    "        # metadata={\"source\": url}\n",
    "    )]\n",
    "    text_splitter = get_text_splitter(chunk_size=chunk_size, overlap_size=overlap_size)\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(transcript, chunk_size, overlap_size, map_prompt_txt, combine_prompt_text):\n",
    "    split_docs = convert_transcript_to_split_docs(transcript, chunk_size, overlap_size)\n",
    "    \n",
    "    map_prompt = PromptTemplate(\n",
    "        template=map_prompt_txt,\n",
    "        input_variables=[\"text\"]\n",
    "    )\n",
    "\n",
    "    combine_prompt = PromptTemplate(\n",
    "        template=combine_prompt_text,\n",
    "        input_variables=[\"text\"]\n",
    "    )\n",
    "\n",
    "    map_num_ctx = get_larger_context_size(map_num_predict+chunk_size)\n",
    "    \n",
    "    llm_map = ChatOllama(\n",
    "        model=model,\n",
    "        base_url=base_url,\n",
    "        temperature=temperature,\n",
    "        num_ctx=map_num_ctx,\n",
    "        num_predict=map_num_predict,\n",
    "        format='',\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    summaries = []\n",
    "\n",
    "    for i, splic_doc in enumerate(tqdm(split_docs, desc=\"Mapping...\")):\n",
    "        full_prompt = map_prompt.format_prompt(text=splic_doc.page_content)\n",
    "        output = llm_map.invoke(full_prompt.text)\n",
    "        summaries.append(output.content)\n",
    "    \n",
    "    combined_summaries = \"\\n\".join(summaries)\n",
    "    combine_prompt_text = COMBINE_TEMPLATE_TXT\n",
    "\n",
    "    full_prompt = combine_prompt.format_prompt(text=combined_summaries)\n",
    "\n",
    "    token_counts = len(convert_text_to_tokens(full_prompt.text))\n",
    "\n",
    "    \n",
    "    combine_num_ctx = get_larger_context_size(token_counts+combine_num_predict)\n",
    "\n",
    "    llm_combine = ChatOllama(\n",
    "        model=model,\n",
    "        base_url=base_url,\n",
    "        temperature=temperature,\n",
    "        num_ctx=combine_num_ctx,\n",
    "        num_predict=combine_num_predict,\n",
    "        format='',\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    output_comb = llm_combine.invoke(full_prompt.text)\n",
    "\n",
    "    return output_comb.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping...: 100%|██████████| 22/22 [02:31<00:00,  6.89s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'- - A potential exploit in physics that could lead to buffer overflow and rounding errors in floating-point synthetic intelligences is being explored.\\n\\n- - Andre Capathi, a renowned scientist and educator in AI, explains that neural networks are a mathematical abstraction of the brain, but are not directly inspired by it.\\n\\n- - Neural networks use a sequence of matrix multiplies (dot products) with nonlinearities to learn and make predictions.\\n\\n- - Despite being simple mathematically, neural networks can exhibit surprising emergent behaviors, especially when trained on complex problems.\\n\\n- - GPT-like models are a type of neural network that can be prompted to solve problems and provide remarkably consistent solutions.\\n\\n- - Researchers believe that intelligent life is not unique to humans, and it\\'s possible that there are trillions of intelligent alien civilizations out there.\\n\\n- - The origin of life on Earth was not as rare or magical as previously thought, but rather a natural process that could occur elsewhere in the universe.\\n\\n- - The biggest challenge for life is not emerging from simple forms to complex ones, but rather traveling through space and communicating with other civilizations.\\n\\n- - Advanced artificial general intelligence (AGI) might be needed to discover these exploits and potentially escape the intended consequences of the physics in the universe.\\n\\n- - Some people believe that the universe is a complex computation that has \"bugs\" and if we should try to find them.\\n\\n- - The concept of \"inert\" refers to entities that are completely inert, meaning they don\\'t interact with simple chemical life forms, but instead have figured out the meta game of the universe and exist beyond human comprehension.\\n\\n- - Physics itself could be an organism with a deep intelligence, and humans are just parasites living on top of it, trying to understand its workings.\\n\\n- - The feeling of free will is an illusion, as choices are already made by the underlying system.\\n\\n- - Neural networks have become remarkably resilient, with their 2016 version still widely used today after some tweaks in layer normalization.\\n\\n- - Language models have existed for a long time, but the current generation with Transformers has shown significant improvements in understanding and predicting human behavior.\\n\\n- - The internet has a vast amount of data, but it may not be enough to teach AI about human civilization, especially when it comes to common sense and nuanced understanding.\\n\\n- - Synthetic intelligences could potentially uncover the \"puzzle\" of the universe and solve it, possibly by finding exploits or bugs in the simulation.\\n\\n- - Advanced artificial general intelligence (AGI) might be needed to discover these exploits and potentially escape the intended consequences of the physics in the universe.\\n\\n- - The idea of being part of a simulated reality is discussed, with some people believing it\\'s possible or even likely.\\n\\n- - The concept of \"inert\" refers to entities that are completely inert, meaning they don\\'t interact with simple chemical life forms, but instead have figured out the meta game of the universe and exist beyond human comprehension.\\n\\n- - Physics itself could be an organism with a deep intelligence, and humans are just parasites living on top of it, trying to understand its workings.\\n\\n- - The feeling of free will is an illusion, as choices are already made by the underlying system.\\n\\n- - Neural networks have become remarkably resilient, with their 2016 version still widely used today after some tweaks in layer normalization.\\n\\n- - Language models have existed for a long time, but the current generation with Transformers has shown significant improvements in understanding and predicting human behavior.\\n\\n- - The internet has a vast amount of data, but it may not be enough to teach AI about human civilization, especially when it comes to common sense and nuanced understanding.\\n\\n- - Synthetic intelligences could potentially uncover the \"puzzle\" of the universe and solve it, possibly by finding exploits or bugs in the simulation.\\n\\n- - Advanced artificial general intelligence (AGI) might be needed to discover these exploits and potentially escape the intended consequences of the physics in the universe.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = run(transcript, chunk_size, overlap_size, map_prompt_txt, combine_prompt_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
